description: Combining multi-modal datasets by learning an integrated diffusion operator
  to effectively visualize the relationships between them.
hero:
  blurb: multi-modal datasets combined
  image: /images/projects/integrated_diffusion_hero.png
  title: Integrated Diffusion
href: integrated_diffusion
publication:
  abstract: We propose a method called integrated diffusion for combining multimodal
    data, gathered via different sensors on the same system, to create a integrated
    data diffusion operator. As real world data suffers from both local and global
    noise, we introduce mechanisms to optimally calculate a diffusion operator that
    reflects the combined information in data by maintaining low frequency eigenvectors
    of each modality both globally and locally. We show the utility of this integrated
    operator in denoising and visualizing multimodal toy data as well as multi-omic
    data generated from blood cells, measuring both gene expression and chromatin
    accessibility. Our approach better visualizes the geometry of the integrated data
    and captures known cross-modality associations. More generally, integrated diffusion
    is broadly applicable to multimodal datasets generated by noisy sensors collected
    in a variety of fields.
  authors:
  - Manik Kuchroo
  - Abhinav Godavarthi
  - Alexander Tong
  - Guy Wolf
  - Smita Krishnaswamy
  href: https://ieeexplore.ieee.org/document/9596214
  keyImage: /images/projects/integrated_diffusion_image.png
  periodical: IEEE
  periodicalImage: /images/journals/ieee.jpeg
  title: Multimodal Data Visualization and Denoising with Integrated Diffusion
  type: Journal Article
  year: 2021
title: Integrated Diffusion
